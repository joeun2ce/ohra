* LLM (qwen3-4b-instruct-2507)     → ml.g6e.xlarge (32GB)
    * max_model_len=8192
* Embedding (qwen3-embedding-gguf) → ml.g5.xlarge (16GB)